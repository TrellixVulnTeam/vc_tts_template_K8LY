# General settings.
spk: "LINE_wContext"

# exp tag(for managing experiments)
tag: "LINE_wContext_6"

sample_rate: 22050

# 1) none 2) tqdm
# NOTE: Jupyterノートブックからrun.shを実行する場合は、none推奨
tqdm: tqdm

# NOTE: benchmarkをtrueにすると、高速化が期待できる分、より多くの
# GPUリソースを必要とする場合があります。
# GPUリソースに余裕がある場合は、true にしてください。
cudnn_benchmark: true
cudnn_deterministic: false

###########################################################
#                DATA PREPARATION SETTING                 #
###########################################################

# PLEASE CHANGE THE PATH BASED ON YOUR ENVIRONMENT
wav_root: "../../../dataset/out_LINE_woITAKO/LINE/wav/22050"
lab_root: "../../../dataset/out_LINE_woITAKO/fullcontext"
dialogue_info: "../../../dataset/out_LINE_woITAKO/dialogue_info.txt"

n_jobs: 8

train_num: 1006
deveval_num: 196
dev_num: 146
eval_num: 50

###########################################################
#                FEATURE EXTRACTION SETTING               #
###########################################################
filter_length: 1024
hop_length: 256
win_length: 1024
n_mel_channels: 80
mel_fmin: 0
mel_fmax: 8000
clip: 0.00001
log_base: "natural"
pitch_phoneme_averaging: 1
energy_phoneme_averaging: 1
accent_info: 1
# for with Contexts
BERT_weight: "colorfulscoop/sbert-base-ja"
use_hist_num: 10
# for with Prosody
# if 0, the latest one is used.
use_local_prosody_hist_idx: 0
# plase replace train/dev/eval to {} for emb_preprocess.py
input_duration_paths: "../fastspeech2/dump/LINE_Teacher_sr22050/norm/{}/out_fastspeech2/duration,../fastspeech2/dump/LINE_MStudent_sr22050/norm/{}/out_fastspeech2/duration,../fastspeech2/dump/LINE_FStudent_sr22050/norm/{}/out_fastspeech2/duration"
output_mel_file_paths: "../fastspeech2/dump/LINE_Teacher_sr22050/norm/{}/out_fastspeech2/mel,../fastspeech2/dump/LINE_MStudent_sr22050/norm/{}/out_fastspeech2/mel,../fastspeech2/dump/LINE_FStudent_sr22050/norm/{}/out_fastspeech2/mel"
model_config_paths: "../fastspeech2/exp/LINE_Teacher_sr22050_LINE_Teacher_1/fastspeech2wGMM/model.yaml,../fastspeech2/exp/LINE_MStudent_sr22050_LINE_MStudent_1/fastspeech2wGMM/model.yaml,../fastspeech2/exp/LINE_FStudent_sr22050_LINE_FStudent_1/fastspeech2wGMM/model.yaml,"
pretrained_checkpoints: "../fastspeech2/exp/LINE_Teacher_sr22050_LINE_Teacher_1/fastspeech2wGMM/latest.pth,../fastspeech2/exp/LINE_MStudent_sr22050_LINE_MStudent_1/fastspeech2wGMM/latest.pth,../fastspeech2/exp/LINE_FStudent_sr22050_LINE_FStudent_1/fastspeech2wGMM/latest.pth"
###########################################################
#                TRAINING SETTING                         #
###########################################################

acoustic_model: fastspeech2wGMMwContexts
vocoder_model: hifigan
# acoustic_modelで利用したいvocoderのconfigやweightへのpathを指定してください.
# 具体的に利用する重みは,vocoder_eval_checkpointになります.
vocoder_config: "conf/train_hifigan/model/hifigan.yaml"
vocoder_weight_base_path: "../fastspeech2/exp/LINE_3_sr22050_LINE_6/hifigan"

### fastspeech2  ###
# max_train_steps: 200000 → nepochs: 256 s.t. batch_size*group_size = 32, JSUT.
fastspeech2_train_nepochs: 250
fastspeech2_data_batch_size: 16

### hifigan ###
hifigan_train_nepochs: 50
hifigan_data_batch_size: 32

### (optional) Optuna Tuning ###
tuning_config: tuning_fastspeech2wContexts

###########################################################
#                SYNTHESIS SETTING                        #
###########################################################

# リストの逆順で発話を処理する
reverse: false

# 生成する発話の数
# -1 の場合、評価の発話をすべて処理する
# 音声生成にかかる時間を短縮する場合、小さな値（5など）に設定してください
num_eval_utts: -1

acoustic_eval_checkpoint: latest.pth
vocoder_eval_checkpoint: latest.pth